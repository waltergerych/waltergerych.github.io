---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

**I'm on the job market in the 2024-2025 academic year!**  

I research machine learning and AI Trusworthiness, with a focus on making models less biased and more reliable. 

Pretrained generative models like ChatGPT have revolutionized the way we do machine learning and are being used in countless fields. But these models have learned biased and spurious correlations that result in real harm --- such as language models associating Black individuals with extremely negative traits and recommending them lower-paying jobs when integrated into job application systems. These models are also poorly calibrated, meaning that they are very confident in their responses even when they are incorrect. My work focuses on fixing these spurious correlations and assigning meaningful uncertainty measures to their predictions, resulting in fairer and more trustworthy systems. 

<!-- My research primarily focuses on performing machine learning on incomplete data, especially in the case where the available data is biased. This includes projects on learning from data with partial or missing labels, as well as
debiasing datasets that underrepresent certain demographics. My main focus is on developing rigorous models of the annotation process itself for correcting and debiasing missing labels ([AAAI 2022](https://ojs.aaai.org/index.php/AAAI/article/view/20624), [SDM 2022](https://epubs.siam.org/doi/pdf/10.1137/1.9781611977172.3)), and applying
generative modeling to correct for biased data samples ([Big Data 2022](https://ieeexplore.ieee.org/document/)).

My work is driven by the development of Human Context Recognition (HCR) systems that identify the *context* (i.e., physical activities and state) of individuals using mobile sensor data. I focus primarily on developing HCR systems that are beneficial to downstream mobile healthcare applications ([IEEE Pervasive Computing 2021](https://ieeexplore.ieee.org/document/9353985)). 
 -->

